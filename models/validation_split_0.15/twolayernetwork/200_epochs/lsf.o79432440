Sender: LSF System <lsfadmin@eu-ms-026-14>
Subject: Job 79432440: <python3 NNtrainer.py> in cluster <euler> Done

Job <python3 NNtrainer.py> was submitted from host <eu-login-24-ng> by user <klugh> in cluster <euler> at Tue Nov 27 19:02:39 2018
Job was executed on host(s) <eu-ms-026-14>, in queue <normal.4h>, as user <klugh> in cluster <euler> at Tue Nov 27 19:02:52 2018
</cluster/home/klugh> was used as the home directory.
</cluster/home/klugh/Python/sensors_project/Sensors_project> was used as the working directory.
Started at Tue Nov 27 19:02:52 2018
Terminated at Tue Nov 27 19:37:15 2018
Results reported at Tue Nov 27 19:37:15 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python3 NNtrainer.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2627.53 sec.
    Max Memory :                                 2918 MB
    Average Memory :                             1894.58 MB
    Total Requested Memory :                     1024.00 MB
    Delta Memory :                               -1894.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                9
    Run time :                                   2066 sec.
    Turnaround time :                            2076 sec.

The output (if any) follows:

2018-11-27 19:02:58.840096: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 192, 448, 32)      608       
_________________________________________________________________
batch_normalization_1 (Batch (None, 192, 448, 32)      128       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 192, 448, 2)       578       
_________________________________________________________________
batch_normalization_2 (Batch (None, 192, 448, 2)       8         
=================================================================
Total params: 1,322
Trainable params: 1,254
Non-trainable params: 68
_________________________________________________________________
Train on 28 samples, validate on 5 samples
Epoch 1/200

28/28 [==============================] - 10s 360ms/step - loss: 1.2302 - acc: 0.4922 - val_loss: 0.8332 - val_acc: 0.5995
Epoch 2/200

28/28 [==============================] - 10s 347ms/step - loss: 1.0504 - acc: 0.5034 - val_loss: 0.8865 - val_acc: 0.5639
Epoch 3/200

28/28 [==============================] - 10s 351ms/step - loss: 0.9783 - acc: 0.4486 - val_loss: 0.8981 - val_acc: 0.4990
Epoch 4/200

28/28 [==============================] - 10s 371ms/step - loss: 0.9040 - acc: 0.4333 - val_loss: 0.8978 - val_acc: 0.4573
Epoch 5/200

28/28 [==============================] - 10s 366ms/step - loss: 0.8482 - acc: 0.4344 - val_loss: 0.8774 - val_acc: 0.4460
Epoch 6/200

28/28 [==============================] - 10s 365ms/step - loss: 0.8382 - acc: 0.4227 - val_loss: 0.8561 - val_acc: 0.4359
Epoch 7/200

28/28 [==============================] - 10s 369ms/step - loss: 0.7675 - acc: 0.4705 - val_loss: 0.8210 - val_acc: 0.4367
Epoch 8/200

28/28 [==============================] - 10s 369ms/step - loss: 0.7133 - acc: 0.5422 - val_loss: 0.7792 - val_acc: 0.4586
Epoch 9/200

28/28 [==============================] - 10s 368ms/step - loss: 0.6808 - acc: 0.6165 - val_loss: 0.7399 - val_acc: 0.5036
Epoch 10/200

28/28 [==============================] - 10s 368ms/step - loss: 0.6378 - acc: 0.7114 - val_loss: 0.6955 - val_acc: 0.6205
Epoch 11/200

28/28 [==============================] - 10s 368ms/step - loss: 0.6100 - acc: 0.7334 - val_loss: 0.6534 - val_acc: 0.6873
Epoch 12/200

28/28 [==============================] - 10s 369ms/step - loss: 0.5759 - acc: 0.7567 - val_loss: 0.6119 - val_acc: 0.7451
Epoch 13/200

28/28 [==============================] - 10s 368ms/step - loss: 0.5793 - acc: 0.7639 - val_loss: 0.5767 - val_acc: 0.8080
Epoch 14/200

28/28 [==============================] - 10s 367ms/step - loss: 0.5635 - acc: 0.7726 - val_loss: 0.5450 - val_acc: 0.8401
Epoch 15/200

28/28 [==============================] - 10s 367ms/step - loss: 0.5405 - acc: 0.7784 - val_loss: 0.5133 - val_acc: 0.8638
Epoch 16/200

28/28 [==============================] - 10s 367ms/step - loss: 0.5308 - acc: 0.7828 - val_loss: 0.4883 - val_acc: 0.8758
Epoch 17/200

28/28 [==============================] - 10s 367ms/step - loss: 0.5192 - acc: 0.7883 - val_loss: 0.4695 - val_acc: 0.8829
Epoch 18/200

28/28 [==============================] - 10s 368ms/step - loss: 0.4932 - acc: 0.7918 - val_loss: 0.4498 - val_acc: 0.8892
Epoch 19/200

28/28 [==============================] - 10s 366ms/step - loss: 0.4901 - acc: 0.7969 - val_loss: 0.4352 - val_acc: 0.8929
Epoch 20/200

28/28 [==============================] - 10s 365ms/step - loss: 0.4827 - acc: 0.8010 - val_loss: 0.4241 - val_acc: 0.8955
Epoch 21/200

28/28 [==============================] - 10s 367ms/step - loss: 0.4634 - acc: 0.8052 - val_loss: 0.4183 - val_acc: 0.8961
Epoch 22/200

28/28 [==============================] - 10s 367ms/step - loss: 0.4418 - acc: 0.8090 - val_loss: 0.4204 - val_acc: 0.8944
Epoch 23/200

28/28 [==============================] - 10s 366ms/step - loss: 0.4076 - acc: 0.8114 - val_loss: 0.4272 - val_acc: 0.8925
Epoch 24/200

28/28 [==============================] - 10s 370ms/step - loss: 0.4065 - acc: 0.8134 - val_loss: 0.4347 - val_acc: 0.8901
Epoch 25/200

28/28 [==============================] - 10s 369ms/step - loss: 0.3984 - acc: 0.8157 - val_loss: 0.4401 - val_acc: 0.8880
Epoch 26/200

28/28 [==============================] - 10s 364ms/step - loss: 0.3840 - acc: 0.8189 - val_loss: 0.4426 - val_acc: 0.8869
Epoch 27/200

28/28 [==============================] - 10s 368ms/step - loss: 0.3792 - acc: 0.8221 - val_loss: 0.4404 - val_acc: 0.8887
Epoch 28/200

28/28 [==============================] - 10s 365ms/step - loss: 0.3817 - acc: 0.8251 - val_loss: 0.4370 - val_acc: 0.8908
Epoch 29/200

28/28 [==============================] - 10s 369ms/step - loss: 0.3586 - acc: 0.8272 - val_loss: 0.4342 - val_acc: 0.8926
Epoch 30/200

28/28 [==============================] - 10s 368ms/step - loss: 0.3489 - acc: 0.8311 - val_loss: 0.4296 - val_acc: 0.8948
Epoch 31/200

28/28 [==============================] - 10s 367ms/step - loss: 0.3330 - acc: 0.8345 - val_loss: 0.4231 - val_acc: 0.8970
Epoch 32/200

28/28 [==============================] - 10s 368ms/step - loss: 0.3251 - acc: 0.8376 - val_loss: 0.4162 - val_acc: 0.8990
Epoch 33/200

28/28 [==============================] - 10s 369ms/step - loss: 0.3063 - acc: 0.8405 - val_loss: 0.4074 - val_acc: 0.9018
Epoch 34/200

28/28 [==============================] - 10s 367ms/step - loss: 0.3023 - acc: 0.8435 - val_loss: 0.4025 - val_acc: 0.9025
Epoch 35/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2955 - acc: 0.8461 - val_loss: 0.3935 - val_acc: 0.9030
Epoch 36/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2934 - acc: 0.8490 - val_loss: 0.3873 - val_acc: 0.9046
Epoch 37/200

28/28 [==============================] - 10s 366ms/step - loss: 0.3000 - acc: 0.8523 - val_loss: 0.3887 - val_acc: 0.9035
Epoch 38/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2915 - acc: 0.8539 - val_loss: 0.3893 - val_acc: 0.9032
Epoch 39/200

28/28 [==============================] - 10s 368ms/step - loss: 0.3111 - acc: 0.8568 - val_loss: 0.3883 - val_acc: 0.9040
Epoch 40/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2871 - acc: 0.8567 - val_loss: 0.3858 - val_acc: 0.9055
Epoch 41/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2750 - acc: 0.8567 - val_loss: 0.3820 - val_acc: 0.9074
Epoch 42/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2797 - acc: 0.8559 - val_loss: 0.3811 - val_acc: 0.9082
Epoch 43/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2698 - acc: 0.8534 - val_loss: 0.3818 - val_acc: 0.9085
Epoch 44/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2631 - acc: 0.8513 - val_loss: 0.3828 - val_acc: 0.9084
Epoch 45/200

28/28 [==============================] - 10s 364ms/step - loss: 0.2622 - acc: 0.8498 - val_loss: 0.3861 - val_acc: 0.9073
Epoch 46/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2550 - acc: 0.8477 - val_loss: 0.3879 - val_acc: 0.9069
Epoch 47/200

28/28 [==============================] - 10s 365ms/step - loss: 0.2633 - acc: 0.8469 - val_loss: 0.3904 - val_acc: 0.9063
Epoch 48/200

28/28 [==============================] - 10s 365ms/step - loss: 0.2666 - acc: 0.8472 - val_loss: 0.3945 - val_acc: 0.9050
Epoch 49/200

28/28 [==============================] - 10s 365ms/step - loss: 0.2453 - acc: 0.8467 - val_loss: 0.3956 - val_acc: 0.9047
Epoch 50/200

28/28 [==============================] - 10s 365ms/step - loss: 0.2410 - acc: 0.8462 - val_loss: 0.3977 - val_acc: 0.9041
Epoch 51/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2275 - acc: 0.8465 - val_loss: 0.3976 - val_acc: 0.9043
Epoch 52/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2230 - acc: 0.8496 - val_loss: 0.3950 - val_acc: 0.9056
Epoch 53/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2187 - acc: 0.8529 - val_loss: 0.3901 - val_acc: 0.9079
Epoch 54/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2110 - acc: 0.8534 - val_loss: 0.3848 - val_acc: 0.9101
Epoch 55/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2156 - acc: 0.8606 - val_loss: 0.3786 - val_acc: 0.9124
Epoch 56/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2161 - acc: 0.8638 - val_loss: 0.3796 - val_acc: 0.9123
Epoch 57/200

28/28 [==============================] - 10s 365ms/step - loss: 0.2125 - acc: 0.8660 - val_loss: 0.3791 - val_acc: 0.9126
Epoch 58/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2138 - acc: 0.8696 - val_loss: 0.3777 - val_acc: 0.9135
Epoch 59/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2040 - acc: 0.8613 - val_loss: 0.3782 - val_acc: 0.9138
Epoch 60/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2009 - acc: 0.8565 - val_loss: 0.3800 - val_acc: 0.9137
Epoch 61/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2002 - acc: 0.8543 - val_loss: 0.3826 - val_acc: 0.9132
Epoch 62/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2049 - acc: 0.8550 - val_loss: 0.3873 - val_acc: 0.9118
Epoch 63/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2055 - acc: 0.8546 - val_loss: 0.3940 - val_acc: 0.9088
Epoch 64/200

28/28 [==============================] - 10s 366ms/step - loss: 0.2066 - acc: 0.8553 - val_loss: 0.4009 - val_acc: 0.9049
Epoch 65/200

28/28 [==============================] - 10s 368ms/step - loss: 0.2052 - acc: 0.8553 - val_loss: 0.4056 - val_acc: 0.9012
Epoch 66/200

28/28 [==============================] - 10s 373ms/step - loss: 0.2039 - acc: 0.8570 - val_loss: 0.4056 - val_acc: 0.9006
Epoch 67/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2166 - acc: 0.8651 - val_loss: 0.4026 - val_acc: 0.9022
Epoch 68/200

28/28 [==============================] - 10s 369ms/step - loss: 0.2193 - acc: 0.8715 - val_loss: 0.3979 - val_acc: 0.9047
Epoch 69/200

28/28 [==============================] - 10s 368ms/step - loss: 0.2244 - acc: 0.8765 - val_loss: 0.3927 - val_acc: 0.9073
Epoch 70/200

28/28 [==============================] - 10s 368ms/step - loss: 0.2187 - acc: 0.8780 - val_loss: 0.3870 - val_acc: 0.9100
Epoch 71/200

28/28 [==============================] - 10s 369ms/step - loss: 0.2125 - acc: 0.8794 - val_loss: 0.3813 - val_acc: 0.9125
Epoch 72/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2137 - acc: 0.8819 - val_loss: 0.3759 - val_acc: 0.9147
Epoch 73/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2143 - acc: 0.8836 - val_loss: 0.3728 - val_acc: 0.9158
Epoch 74/200

28/28 [==============================] - 10s 370ms/step - loss: 0.2142 - acc: 0.8844 - val_loss: 0.3692 - val_acc: 0.9173
Epoch 75/200

28/28 [==============================] - 10s 368ms/step - loss: 0.2162 - acc: 0.8855 - val_loss: 0.3645 - val_acc: 0.9193
Epoch 76/200

28/28 [==============================] - 10s 371ms/step - loss: 0.2144 - acc: 0.8860 - val_loss: 0.3588 - val_acc: 0.9214
Epoch 77/200

28/28 [==============================] - 10s 370ms/step - loss: 0.2130 - acc: 0.8866 - val_loss: 0.3532 - val_acc: 0.9233
Epoch 78/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2122 - acc: 0.8873 - val_loss: 0.3459 - val_acc: 0.9252
Epoch 79/200

28/28 [==============================] - 10s 365ms/step - loss: 0.2016 - acc: 0.8858 - val_loss: 0.3395 - val_acc: 0.9267
Epoch 80/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1988 - acc: 0.8865 - val_loss: 0.3319 - val_acc: 0.9281
Epoch 81/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1974 - acc: 0.8864 - val_loss: 0.3298 - val_acc: 0.9284
Epoch 82/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1976 - acc: 0.8858 - val_loss: 0.3259 - val_acc: 0.9287
Epoch 83/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1995 - acc: 0.8851 - val_loss: 0.3218 - val_acc: 0.9291
Epoch 84/200

28/28 [==============================] - 10s 367ms/step - loss: 0.2014 - acc: 0.8849 - val_loss: 0.3116 - val_acc: 0.9299
Epoch 85/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1978 - acc: 0.8845 - val_loss: 0.3028 - val_acc: 0.9303
Epoch 86/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1970 - acc: 0.8853 - val_loss: 0.2963 - val_acc: 0.9307
Epoch 87/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1964 - acc: 0.8870 - val_loss: 0.2915 - val_acc: 0.9309
Epoch 88/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1891 - acc: 0.8873 - val_loss: 0.2900 - val_acc: 0.9308
Epoch 89/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1836 - acc: 0.8882 - val_loss: 0.2891 - val_acc: 0.9308
Epoch 90/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1827 - acc: 0.8888 - val_loss: 0.2864 - val_acc: 0.9309
Epoch 91/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1821 - acc: 0.8891 - val_loss: 0.2836 - val_acc: 0.9308
Epoch 92/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1813 - acc: 0.8893 - val_loss: 0.2813 - val_acc: 0.9308
Epoch 93/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1797 - acc: 0.8887 - val_loss: 0.2775 - val_acc: 0.9308
Epoch 94/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1794 - acc: 0.8888 - val_loss: 0.2749 - val_acc: 0.9307
Epoch 95/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1776 - acc: 0.8876 - val_loss: 0.2848 - val_acc: 0.9303
Epoch 96/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1777 - acc: 0.8857 - val_loss: 0.2922 - val_acc: 0.9301
Epoch 97/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1846 - acc: 0.8852 - val_loss: 0.3024 - val_acc: 0.9298
Epoch 98/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1914 - acc: 0.8845 - val_loss: 0.3067 - val_acc: 0.9298
Epoch 99/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1961 - acc: 0.8837 - val_loss: 0.3085 - val_acc: 0.9299
Epoch 100/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1986 - acc: 0.8829 - val_loss: 0.3061 - val_acc: 0.9300
Epoch 101/200

28/28 [==============================] - 10s 365ms/step - loss: 0.2021 - acc: 0.8831 - val_loss: 0.3005 - val_acc: 0.9303
Epoch 102/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1951 - acc: 0.8814 - val_loss: 0.2921 - val_acc: 0.9305
Epoch 103/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1937 - acc: 0.8823 - val_loss: 0.2823 - val_acc: 0.9308
Epoch 104/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1902 - acc: 0.8828 - val_loss: 0.2711 - val_acc: 0.9310
Epoch 105/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1805 - acc: 0.8822 - val_loss: 0.2576 - val_acc: 0.9313
Epoch 106/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1771 - acc: 0.8838 - val_loss: 0.2431 - val_acc: 0.9318
Epoch 107/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1703 - acc: 0.8834 - val_loss: 0.2284 - val_acc: 0.9322
Epoch 108/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1701 - acc: 0.8832 - val_loss: 0.2173 - val_acc: 0.9326
Epoch 109/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1715 - acc: 0.8855 - val_loss: 0.2100 - val_acc: 0.9329
Epoch 110/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1730 - acc: 0.8853 - val_loss: 0.2047 - val_acc: 0.9332
Epoch 111/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1742 - acc: 0.8863 - val_loss: 0.2017 - val_acc: 0.9334
Epoch 112/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1746 - acc: 0.8873 - val_loss: 0.2018 - val_acc: 0.9336
Epoch 113/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1748 - acc: 0.8842 - val_loss: 0.2183 - val_acc: 0.9336
Epoch 114/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1722 - acc: 0.8821 - val_loss: 0.2350 - val_acc: 0.9336
Epoch 115/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1695 - acc: 0.8834 - val_loss: 0.2525 - val_acc: 0.9335
Epoch 116/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1712 - acc: 0.8826 - val_loss: 0.2667 - val_acc: 0.9334
Epoch 117/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1758 - acc: 0.8825 - val_loss: 0.2779 - val_acc: 0.9333
Epoch 118/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1820 - acc: 0.8835 - val_loss: 0.2863 - val_acc: 0.9332
Epoch 119/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1852 - acc: 0.8836 - val_loss: 0.2914 - val_acc: 0.9332
Epoch 120/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1884 - acc: 0.8835 - val_loss: 0.2940 - val_acc: 0.9331
Epoch 121/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1882 - acc: 0.8840 - val_loss: 0.2946 - val_acc: 0.9330
Epoch 122/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1860 - acc: 0.8838 - val_loss: 0.2924 - val_acc: 0.9331
Epoch 123/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1844 - acc: 0.8839 - val_loss: 0.2889 - val_acc: 0.9331
Epoch 124/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1786 - acc: 0.8835 - val_loss: 0.2829 - val_acc: 0.9332
Epoch 125/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1759 - acc: 0.8834 - val_loss: 0.2749 - val_acc: 0.9335
Epoch 126/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1674 - acc: 0.8823 - val_loss: 0.2663 - val_acc: 0.9336
Epoch 127/200

28/28 [==============================] - 10s 363ms/step - loss: 0.1656 - acc: 0.8819 - val_loss: 0.2594 - val_acc: 0.9338
Epoch 128/200

28/28 [==============================] - 10s 364ms/step - loss: 0.1661 - acc: 0.8814 - val_loss: 0.2580 - val_acc: 0.9338
Epoch 129/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1688 - acc: 0.8808 - val_loss: 0.2582 - val_acc: 0.9338
Epoch 130/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1691 - acc: 0.8805 - val_loss: 0.2588 - val_acc: 0.9339
Epoch 131/200

28/28 [==============================] - 10s 364ms/step - loss: 0.1672 - acc: 0.8806 - val_loss: 0.2591 - val_acc: 0.9340
Epoch 132/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1657 - acc: 0.8811 - val_loss: 0.2595 - val_acc: 0.9341
Epoch 133/200

28/28 [==============================] - 10s 364ms/step - loss: 0.1661 - acc: 0.8819 - val_loss: 0.2600 - val_acc: 0.9343
Epoch 134/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1661 - acc: 0.8821 - val_loss: 0.2610 - val_acc: 0.9344
Epoch 135/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1654 - acc: 0.8820 - val_loss: 0.2612 - val_acc: 0.9343
Epoch 136/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1653 - acc: 0.8823 - val_loss: 0.2601 - val_acc: 0.9341
Epoch 137/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1652 - acc: 0.8820 - val_loss: 0.2593 - val_acc: 0.9339
Epoch 138/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1647 - acc: 0.8813 - val_loss: 0.2575 - val_acc: 0.9338
Epoch 139/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1644 - acc: 0.8815 - val_loss: 0.2561 - val_acc: 0.9336
Epoch 140/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1678 - acc: 0.8797 - val_loss: 0.2567 - val_acc: 0.9334
Epoch 141/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1716 - acc: 0.8783 - val_loss: 0.2587 - val_acc: 0.9333
Epoch 142/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1750 - acc: 0.8779 - val_loss: 0.2587 - val_acc: 0.9333
Epoch 143/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1766 - acc: 0.8784 - val_loss: 0.2580 - val_acc: 0.9333
Epoch 144/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1746 - acc: 0.8795 - val_loss: 0.2445 - val_acc: 0.9338
Epoch 145/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1641 - acc: 0.8804 - val_loss: 0.2330 - val_acc: 0.9341
Epoch 146/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1652 - acc: 0.8812 - val_loss: 0.2247 - val_acc: 0.9345
Epoch 147/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1669 - acc: 0.8798 - val_loss: 0.2187 - val_acc: 0.9348
Epoch 148/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1681 - acc: 0.8809 - val_loss: 0.2152 - val_acc: 0.9350
Epoch 149/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1686 - acc: 0.8800 - val_loss: 0.2149 - val_acc: 0.9351
Epoch 150/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1687 - acc: 0.8808 - val_loss: 0.2164 - val_acc: 0.9351
Epoch 151/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1677 - acc: 0.8811 - val_loss: 0.2185 - val_acc: 0.9351
Epoch 152/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1661 - acc: 0.8810 - val_loss: 0.2218 - val_acc: 0.9351
Epoch 153/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1647 - acc: 0.8829 - val_loss: 0.2229 - val_acc: 0.9354
Epoch 154/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1687 - acc: 0.8818 - val_loss: 0.2228 - val_acc: 0.9356
Epoch 155/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1751 - acc: 0.8807 - val_loss: 0.2220 - val_acc: 0.9359
Epoch 156/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1776 - acc: 0.8801 - val_loss: 0.2219 - val_acc: 0.9361
Epoch 157/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1806 - acc: 0.8805 - val_loss: 0.2223 - val_acc: 0.9364
Epoch 158/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1813 - acc: 0.8813 - val_loss: 0.2224 - val_acc: 0.9367
Epoch 159/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1769 - acc: 0.8822 - val_loss: 0.2233 - val_acc: 0.9370
Epoch 160/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1742 - acc: 0.8839 - val_loss: 0.2243 - val_acc: 0.9373
Epoch 161/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1720 - acc: 0.8867 - val_loss: 0.2251 - val_acc: 0.9376
Epoch 162/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1703 - acc: 0.8882 - val_loss: 0.2241 - val_acc: 0.9376
Epoch 163/200

28/28 [==============================] - 10s 371ms/step - loss: 0.1710 - acc: 0.8941 - val_loss: 0.2225 - val_acc: 0.9377
Epoch 164/200

28/28 [==============================] - 10s 366ms/step - loss: 0.1732 - acc: 0.8993 - val_loss: 0.2216 - val_acc: 0.9378
Epoch 165/200

28/28 [==============================] - 10s 347ms/step - loss: 0.1735 - acc: 0.9010 - val_loss: 0.2207 - val_acc: 0.9379
Epoch 166/200

28/28 [==============================] - 10s 354ms/step - loss: 0.1729 - acc: 0.9021 - val_loss: 0.2191 - val_acc: 0.9379
Epoch 167/200

28/28 [==============================] - 10s 364ms/step - loss: 0.1734 - acc: 0.9065 - val_loss: 0.2178 - val_acc: 0.9379
Epoch 168/200

28/28 [==============================] - 10s 368ms/step - loss: 0.1739 - acc: 0.9076 - val_loss: 0.2161 - val_acc: 0.9379
Epoch 169/200

28/28 [==============================] - 10s 372ms/step - loss: 0.1761 - acc: 0.9128 - val_loss: 0.2140 - val_acc: 0.9379
Epoch 170/200

28/28 [==============================] - 11s 378ms/step - loss: 0.1775 - acc: 0.9146 - val_loss: 0.2134 - val_acc: 0.9379
Epoch 171/200

28/28 [==============================] - 10s 374ms/step - loss: 0.1789 - acc: 0.9156 - val_loss: 0.2132 - val_acc: 0.9378
Epoch 172/200

28/28 [==============================] - 10s 374ms/step - loss: 0.1789 - acc: 0.9160 - val_loss: 0.2137 - val_acc: 0.9378
Epoch 173/200

28/28 [==============================] - 10s 373ms/step - loss: 0.1784 - acc: 0.9163 - val_loss: 0.2141 - val_acc: 0.9377
Epoch 174/200

28/28 [==============================] - 10s 370ms/step - loss: 0.1778 - acc: 0.9161 - val_loss: 0.2159 - val_acc: 0.9376
Epoch 175/200

28/28 [==============================] - 10s 373ms/step - loss: 0.1776 - acc: 0.9151 - val_loss: 0.2183 - val_acc: 0.9374
Epoch 176/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1754 - acc: 0.9152 - val_loss: 0.2220 - val_acc: 0.9373
Epoch 177/200

28/28 [==============================] - 10s 371ms/step - loss: 0.1794 - acc: 0.9159 - val_loss: 0.2253 - val_acc: 0.9372
Epoch 178/200

28/28 [==============================] - 10s 371ms/step - loss: 0.1765 - acc: 0.9073 - val_loss: 0.2294 - val_acc: 0.9371
Epoch 179/200

28/28 [==============================] - 10s 370ms/step - loss: 0.1770 - acc: 0.9056 - val_loss: 0.2332 - val_acc: 0.9369
Epoch 180/200

28/28 [==============================] - 10s 370ms/step - loss: 0.1741 - acc: 0.9007 - val_loss: 0.2357 - val_acc: 0.9368
Epoch 181/200

28/28 [==============================] - 10s 370ms/step - loss: 0.1783 - acc: 0.9001 - val_loss: 0.2386 - val_acc: 0.9367
Epoch 182/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1780 - acc: 0.8978 - val_loss: 0.2415 - val_acc: 0.9366
Epoch 183/200

28/28 [==============================] - 10s 349ms/step - loss: 0.1807 - acc: 0.8976 - val_loss: 0.2443 - val_acc: 0.9365
Epoch 184/200

28/28 [==============================] - 10s 370ms/step - loss: 0.1721 - acc: 0.8940 - val_loss: 0.2460 - val_acc: 0.9365
Epoch 185/200

28/28 [==============================] - 10s 373ms/step - loss: 0.1746 - acc: 0.8955 - val_loss: 0.2449 - val_acc: 0.9366
Epoch 186/200

28/28 [==============================] - 10s 372ms/step - loss: 0.1671 - acc: 0.8939 - val_loss: 0.2449 - val_acc: 0.9360
Epoch 187/200

28/28 [==============================] - 10s 372ms/step - loss: 0.1755 - acc: 0.8919 - val_loss: 0.2451 - val_acc: 0.9354
Epoch 188/200

28/28 [==============================] - 10s 372ms/step - loss: 0.1741 - acc: 0.8836 - val_loss: 0.2453 - val_acc: 0.9349
Epoch 189/200

28/28 [==============================] - 10s 371ms/step - loss: 0.1695 - acc: 0.8897 - val_loss: 0.2452 - val_acc: 0.9344
Epoch 190/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1747 - acc: 0.8862 - val_loss: 0.2442 - val_acc: 0.9338
Epoch 191/200

28/28 [==============================] - 10s 373ms/step - loss: 0.1700 - acc: 0.8901 - val_loss: 0.2447 - val_acc: 0.9335
Epoch 192/200

28/28 [==============================] - 10s 370ms/step - loss: 0.1750 - acc: 0.8912 - val_loss: 0.2464 - val_acc: 0.9330
Epoch 193/200

28/28 [==============================] - 10s 370ms/step - loss: 0.1811 - acc: 0.8907 - val_loss: 0.2508 - val_acc: 0.9323
Epoch 194/200

28/28 [==============================] - 10s 372ms/step - loss: 0.1738 - acc: 0.8910 - val_loss: 0.2570 - val_acc: 0.9316
Epoch 195/200

28/28 [==============================] - 10s 371ms/step - loss: 0.1836 - acc: 0.8926 - val_loss: 0.2684 - val_acc: 0.9305
Epoch 196/200

28/28 [==============================] - 10s 371ms/step - loss: 0.1815 - acc: 0.8942 - val_loss: 0.2821 - val_acc: 0.9291
Epoch 197/200

28/28 [==============================] - 10s 372ms/step - loss: 0.1853 - acc: 0.8961 - val_loss: 0.2998 - val_acc: 0.9272
Epoch 198/200

28/28 [==============================] - 10s 369ms/step - loss: 0.1822 - acc: 0.8997 - val_loss: 0.3189 - val_acc: 0.9246
Epoch 199/200

28/28 [==============================] - 10s 367ms/step - loss: 0.1689 - acc: 0.9022 - val_loss: 0.3404 - val_acc: 0.9208
Epoch 200/200

28/28 [==============================] - 10s 365ms/step - loss: 0.1656 - acc: 0.9018 - val_loss: 0.3639 - val_acc: 0.9152
Using TensorFlow backend.
NNtrainer.py:64: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  history = model.fit(x_train, y_train, validation_split=0.15, batch_size=batch_size, nb_epoch=epochs, verbose=1)
dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])
